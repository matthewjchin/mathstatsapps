{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26410, 25)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mar1=pd.read_csv('marathon_results_2017.csv')\n",
    "# mar1.columns\n",
    "mar1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26598, 25)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mar2=pd.read_csv('marathon_results_2015.csv')\n",
    "# mar2.columns\n",
    "mar2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question #1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since times/paces are written with colons in between of type String, \n",
    "# take out colons out of string and make array of hours, minutes, seconds\n",
    "def f(x):\n",
    "    return x.split(\":\")\n",
    "\n",
    "# convert any hours and seconds into minutes using the to_minutes function\n",
    "def to_minutes(x):\n",
    "    return (int(x[0])*3600+int(x[1])*60+int(x[2]))/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sample size n = 50\n",
    "# take sample size based on 2017 results\n",
    "\n",
    "mar1['PaceList']=mar1['Pace'].apply(f)\n",
    "mar1['PaceMinutes']=mar1['PaceList'].apply(to_minutes)\n",
    "\n",
    "mar2['PaceList']=mar2['Pace'].apply(f)\n",
    "mar2['PaceMinutes']=mar2['PaceList'].apply(to_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of n=50, 100, 1000 runners from the 2017 and 2015 marathon results \n",
    "# and find average pace of two years\n",
    "\n",
    "# 2017 results\n",
    "df50_17 = mar1.sample(50)\n",
    "df100_17 = mar1.sample(100)\n",
    "df1000_17 = mar1.sample(1000)\n",
    "\n",
    "# 2015 results\n",
    "df50_15 = mar2.sample(50)\n",
    "df100_15 = mar2.sample(100)\n",
    "df1000_15 = mar2.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=50 (2017): 8.865000000000002 | n=100 (2017): 9.326 | n=1000 (2017): 9.132899999999994 \n",
      "\n",
      "n=50 (2015): 8.49633333333333 | n=100 (2015): 8.945833333333335 | n=1000 (2015): 8.65811666666667\n"
     ]
    }
   ],
   "source": [
    "# Series of t-values for t-confidence interval for n=50,100,1000\n",
    "# best to use a confidence interval using t-distribution based on size of sample sets \n",
    "# This is for 95% confidence intervals, where no more than 5% of times the CI misses true mean\n",
    "\n",
    "# T-distribution, 2017\n",
    "tval50_17 = stats.t.ppf(0.975,50)\n",
    "tval100_17= stats.t.ppf(0.975,100)\n",
    "tval1000_17= stats.t.ppf(0.975,1000)\n",
    "\n",
    "# T-distribution, 2015\n",
    "tval50_15 = stats.t.ppf(0.975,50)\n",
    "tval100_15 = stats.t.ppf(0.975,100)\n",
    "tval1000_15 = stats.t.ppf(0.975,1000)\n",
    "\n",
    "# True population standard deviation for 2017, 2015 data\n",
    "psd1 = mar1['PaceMinutes'].std()\n",
    "psd2 = mar2['PaceMinutes'].std()\n",
    "\n",
    "# Print out the sample mean\n",
    "print(\"n=50 (2017):\", df50_17['PaceMinutes'].mean(), \n",
    "      \"| n=100 (2017):\", df100_17['PaceMinutes'].mean(), \n",
    "      \"| n=1000 (2017):\", df1000_17['PaceMinutes'].mean(),\n",
    "      \"\\n\\nn=50 (2015):\", df50_15['PaceMinutes'].mean(),\n",
    "      \"| n=100 (2015):\", df100_15['PaceMinutes'].mean(),\n",
    "      \"| n=1000 (2015):\", df1000_15['PaceMinutes'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017:\t ( 8.408364213903534 , 9.32163578609647 )\n",
      "2015:\t ( 8.057456757304001 , 8.93520990936266 )\n"
     ]
    }
   ],
   "source": [
    "# sample mean, 2017, n=50\n",
    "xbar_17=df50_17['PaceMinutes'].mean()\n",
    "\n",
    "# sample mean, 2015, n=50\n",
    "xbar_15=df50_15['PaceMinutes'].mean()\n",
    "\n",
    "# CI range, 2017, n=50\n",
    "low50_17=xbar_17-((tval50_17*psd1)/np.sqrt(50))\n",
    "high50_17=xbar_17+((tval50_17*psd1)/np.sqrt(50))\n",
    "print(\"2017:\\t (\",low50_17,\",\",high50_17,\")\")\n",
    "\n",
    "# CI range, 2015, n=50\n",
    "low50_15=xbar_15-((tval50_15*psd2)/np.sqrt(50))\n",
    "high50_15=xbar_15+((tval50_15*psd2)/np.sqrt(50))\n",
    "print(\"2015:\\t (\",low50_15,\",\",high50_15,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017:\t ( 9.007062370495023 , 9.644937629504978 )\n",
      "2015:\t ( 8.639299638283678 , 9.252367028382992 )\n"
     ]
    }
   ],
   "source": [
    "# sample mean, 2017, n=100\n",
    "xbar_17=df100_17['PaceMinutes'].mean()\n",
    "\n",
    "# sample mean, 2015, n=100\n",
    "xbar_15=df100_15['PaceMinutes'].mean()\n",
    "\n",
    "# CI range, 2017, n=100\n",
    "low100_17=xbar_17-((tval100_17*psd1)/np.sqrt(100))\n",
    "high100_17=xbar_17+((tval100_17*psd1)/np.sqrt(100))\n",
    "print(\"2017:\\t (\",low100_17,\",\",high100_17,\")\")\n",
    "\n",
    "# CI range, 2015, n=100\n",
    "low100_15=xbar_15-((tval100_15*psd2)/np.sqrt(100))\n",
    "high100_15=xbar_15+((tval100_15*psd2)/np.sqrt(100))\n",
    "print(\"2015:\\t (\",low100_15,\",\",high100_15,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017:\t ( 9.033142769882891 , 9.232657230117097 )\n",
      "2015:\t ( 8.562239135993428 , 8.753994197339912 )\n"
     ]
    }
   ],
   "source": [
    "# sample mean, 2017, n=1000\n",
    "xbar_17=df1000_17['PaceMinutes'].mean()\n",
    "\n",
    "# sample mean, 2015, n=1000\n",
    "xbar_15=df1000_15['PaceMinutes'].mean()\n",
    "\n",
    "# CI range, 2017, n=1000\n",
    "low1000_17=xbar_17-((tval1000_17*psd1)/np.sqrt(1000))\n",
    "high1000_17=xbar_17+((tval1000_17*psd1)/np.sqrt(1000))\n",
    "print(\"2017:\\t (\",low1000_17,\",\",high1000_17,\")\")\n",
    "\n",
    "# CI range, 2015, n=1000\n",
    "low1000_15=xbar_15-((tval1000_15*psd2)/np.sqrt(1000))\n",
    "high1000_15=xbar_15+((tval1000_15*psd2)/np.sqrt(1000))\n",
    "print(\"2015:\\t (\",low1000_15,\",\",high1000_15,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series of t-values for t-confidence interval for n=50,100,1000\n",
    "# best to use a confidence interval using t-distribution based on size of sample sets \n",
    "# This is for 90% confidence intervals, where no more than 10% of times the CI \n",
    "# misses the true mean\n",
    "\n",
    "# T-distribution, 2017\n",
    "tval50_17 = stats.t.ppf(0.95,50)\n",
    "tval100_17=stats.t.ppf(0.95,100)\n",
    "tval1000_17=stats.t.ppf(0.95,1000)\n",
    "\n",
    "# T-distribution, 2015\n",
    "tval50_15 = stats.t.ppf(0.95,50)\n",
    "tval100_15 = stats.t.ppf(0.95,100)\n",
    "tval1000_15 = stats.t.ppf(0.95,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017:\t ( 8.483991442872188 , 9.246008557127816 )\n",
      "2015:\t ( 8.130142736622622 , 8.86252393004404 )\n"
     ]
    }
   ],
   "source": [
    "# sample mean, 2017, n=50\n",
    "xbar_17=df50_17['PaceMinutes'].mean()\n",
    "\n",
    "# sample mean, 2015, n=50\n",
    "xbar_15=df50_15['PaceMinutes'].mean()\n",
    "\n",
    "# CI range, 2017, n=50\n",
    "low50_17=xbar_17-((tval50_17*psd1)/np.sqrt(50))\n",
    "high50_17=xbar_17+((tval50_17*psd1)/np.sqrt(50))\n",
    "print(\"2017:\\t (\",low50_17,\",\",high50_17,\")\")\n",
    "\n",
    "# CI range, 2015, n=50\n",
    "low50_15=xbar_15-((tval50_15*psd2)/np.sqrt(50))\n",
    "high50_15=xbar_15+((tval50_15*psd2)/np.sqrt(50))\n",
    "print(\"2015:\\t (\",low50_15,\",\",high50_15,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017:\t ( 9.059105442566036 , 9.592894557433965 )\n",
      "2015:\t ( 8.689318681845341 , 9.202347984821328 )\n"
     ]
    }
   ],
   "source": [
    "# sample mean, 2017, n=100\n",
    "xbar_17=df100_17['PaceMinutes'].mean()\n",
    "\n",
    "# sample mean, 2015, n=100\n",
    "xbar_15=df100_15['PaceMinutes'].mean()\n",
    "\n",
    "# CI range, 2017, n=100\n",
    "low100_17=xbar_17-((tval100_17*psd1)/np.sqrt(100))\n",
    "high100_17=xbar_17+((tval100_17*psd1)/np.sqrt(100))\n",
    "print(\"2017:\\t (\",low100_17,\",\",high100_17,\")\")\n",
    "\n",
    "# CI range, 2015, n=100\n",
    "low100_15=xbar_15-((tval100_15*psd2)/np.sqrt(100))\n",
    "high100_15=xbar_15+((tval100_15*psd2)/np.sqrt(100))\n",
    "print(\"2015:\\t (\",low100_15,\",\",high100_15,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017:\t ( 9.04920488729465 , 9.216595112705338 )\n",
      "2015:\t ( 8.577676574994243 , 8.738556758339097 )\n"
     ]
    }
   ],
   "source": [
    "# sample mean, 2017, n=1000\n",
    "xbar_17=df1000_17['PaceMinutes'].mean()\n",
    "\n",
    "# sample mean, 2015, n=1000\n",
    "xbar_15=df1000_15['PaceMinutes'].mean()\n",
    "\n",
    "# CI range, 2017, n=1000\n",
    "low1000_17=xbar_17-((tval1000_17*psd1)/np.sqrt(1000))\n",
    "high1000_17=xbar_17+((tval1000_17*psd1)/np.sqrt(1000))\n",
    "print(\"2017:\\t (\",low1000_17,\",\",high1000_17,\")\")\n",
    "\n",
    "# CI range, 2015, n=1000\n",
    "low1000_15=xbar_15-((tval1000_15*psd2)/np.sqrt(1000))\n",
    "high1000_15=xbar_15+((tval1000_15*psd2)/np.sqrt(1000))\n",
    "print(\"2015:\\t (\",low1000_15,\",\",high1000_15,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7620171142556273"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high50_17-low50_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.533789114867929"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high100_17-low100_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1673902254106885"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high1000_17-low1000_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323811934214177"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high50_15-low50_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5130293029759869"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high100_15-low100_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16088018334485454"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high1000_15-low1000_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these two years, based on the samples taken, there seems to be a more beneficial advangtage to the runners in the 2015 race. Depending on the random number of samples, the average mile paces in 2015 were about 0.03 minutes (1.8 seconds) faster than the mile paces in the 2017 running. Thus, there was little difference overall when comparing the 2017 results to the 2015 results with respect to mile pace and the number of people taken as part of a sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question #2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.087952795658213\n"
     ]
    }
   ],
   "source": [
    "# Overall mile pace mean in minutes, 2017\n",
    "print(mar1[\"PaceMinutes\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take samples of 20,50,100,1000\n",
    "# Use mar1\n",
    "df20= mar1.sample(20)\n",
    "df50= mar1.sample(50)\n",
    "df100= mar1.sample(100)\n",
    "df1000= mar1.sample(1000)\n",
    "\n",
    "# For 90% CI using the T-distribution for each sample of 2017 results. \n",
    "# No more than 10% of CIs are to be outside of the true mean\n",
    "tval20= stats.t.ppf(0.95,20)\n",
    "tval50= stats.t.ppf(0.95,50)\n",
    "tval100= stats.t.ppf(0.95,100)\n",
    "tval1000= stats.t.ppf(0.95,1000)\n",
    "\n",
    "mar1['PaceList']=mar1['Pace'].apply(f)\n",
    "mar1['PaceMinutes']=mar1['PaceList'].apply(to_minutes)\n",
    "\n",
    "list_df20 = np.array(df20['M/F'])\n",
    "times20 = np.array(df20['PaceMinutes'])\n",
    "\n",
    "list_df50 = np.array(df50['M/F']) \n",
    "times50 = np.array(df50['PaceMinutes'])\n",
    "\n",
    "list_df100 = np.array(df100['M/F']) \n",
    "times100 = np.array(df100['PaceMinutes'])\n",
    "\n",
    "list_df1000 = np.array(df1000['M/F']) \n",
    "times1000 = np.array(df1000['PaceMinutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 , 64.31666666666666 , mean: 9.188095238095238\n"
     ]
    }
   ],
   "source": [
    "# For each sample set, find how many females found and find mean pace time\n",
    "c20=0\n",
    "sum20=0\n",
    "for i in range(20):\n",
    "    if list_df20[i] == 'F':\n",
    "        c20+=1\n",
    "        sum20+= times20[i]\n",
    "m1=sum20/c20\n",
    "print(c20,\",\", sum20, \", mean:\",m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 , 154.33333333333334 , mean: 9.645833333333334\n"
     ]
    }
   ],
   "source": [
    "c50=0\n",
    "sum50=0\n",
    "for i in range(50):\n",
    "    if list_df50[i] == 'F':\n",
    "        c50+=1\n",
    "        sum50+=times50[i]\n",
    "m2=sum50/c50\n",
    "print(c50,\",\", sum50, \", mean:\", m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 , 440.7666666666666 mean: 9.581884057971013\n"
     ]
    }
   ],
   "source": [
    "c100=0\n",
    "sum100=0\n",
    "for i in range(100):\n",
    "    if list_df100[i] == 'F':\n",
    "        c100+=1\n",
    "        sum100+=times100[i]\n",
    "m3=sum100/c100\n",
    "print(c100,\",\",sum100, \"mean:\",m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471 , 4464.983333333335 , mean: 9.479794762915786\n"
     ]
    }
   ],
   "source": [
    "c1000=0\n",
    "sum1k=0\n",
    "for i in range(1000):\n",
    "    if list_df1000[i] == 'F':\n",
    "        c1000+=1\n",
    "        sum1k+=times1000[i]\n",
    "m4=sum1k/c1000\n",
    "print(c1000,\",\", sum1k, \", mean:\", m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F n=20: 9.188095238095238 \n",
      "Mean F n=50: 9.645833333333334 \n",
      "Mean F n=100: 9.581884057971013 \n",
      "Mean F n=1000: 9.479794762915786\n"
     ]
    }
   ],
   "source": [
    "# Again, return all female runners' mile pace times and compare to \n",
    "# true sample means with respect to n\n",
    "\n",
    "print(\"Mean F n=20:\",m1,\n",
    "     \"\\nMean F n=50:\",m2,\n",
    "     \"\\nMean F n=100:\",m3,\n",
    "     \"\\nMean F n=1000:\",m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=20: 8.810833333333333 \n",
      "n=50: 8.851666666666667 \n",
      "n=100: 9.224166666666667 \n",
      "n=1000: 9.099233333333332\n"
     ]
    }
   ],
   "source": [
    "# True sample means for n\n",
    "print(\"n=20:\",df20['PaceMinutes'].mean(),\n",
    "     \"\\nn=50:\", df50['PaceMinutes'].mean(),\n",
    "     \"\\nn=100:\", df100['PaceMinutes'].mean(),\n",
    "     \"\\nn=1000:\", df1000['PaceMinutes'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 8.221134917054062 , high: 9.400531749612604\n"
     ]
    }
   ],
   "source": [
    "sm = df20[\"PaceMinutes\"].mean()\n",
    "psd = df20[\"PaceMinutes\"].std()\n",
    "low20=sm-((tval20*psd)/np.sqrt(20))\n",
    "hi20=sm+((tval20*psd)/np.sqrt(20))\n",
    "print(\"low:\", low20, \", high:\", hi20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 8.454755508532795 , high: 9.248577824800538\n"
     ]
    }
   ],
   "source": [
    "sm = df50[\"PaceMinutes\"].mean()\n",
    "psd = df50[\"PaceMinutes\"].std()\n",
    "low50=sm-((tval50*psd)/np.sqrt(50))\n",
    "hi50=sm+((tval50*psd)/np.sqrt(50))\n",
    "print(\"low:\", low50, \", high:\", hi50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 8.948799813947486 , high: 9.499533519385848\n"
     ]
    }
   ],
   "source": [
    "sm = df100[\"PaceMinutes\"].mean()\n",
    "psd = df100[\"PaceMinutes\"].std()\n",
    "low100=sm-((tval100*psd)/np.sqrt(100))\n",
    "hi100=sm+((tval100*psd)/np.sqrt(100))\n",
    "print(\"low:\", low100, \", high:\", hi100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 9.016466660625005 , high: 9.18200000604166\n"
     ]
    }
   ],
   "source": [
    "sm = df1000[\"PaceMinutes\"].mean()\n",
    "psd = df1000[\"PaceMinutes\"].std()\n",
    "low1000=sm-((tval1000*psd)/np.sqrt(1000))\n",
    "hi1000=sm+((tval1000*psd)/np.sqrt(1000))\n",
    "print(\"low:\", low1000, \", high:\", hi1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9903312268076245 0.4360923021578653 1.4264235289654899\n"
     ]
    }
   ],
   "source": [
    "print(mar1[\"PaceMinutes\"].mean()-low20,\n",
    "     hi20-mar1[\"PaceMinutes\"].mean(),\n",
    "     hi20-low20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7119810584472113 0.23940880046411905 0.9513898589113303\n"
     ]
    }
   ],
   "source": [
    "print(mar1[\"PaceMinutes\"].mean()-low50,\n",
    "     hi50-mar1[\"PaceMinutes\"].mean(),\n",
    "     hi50-low50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19284810798012764 0.4652758499970364 0.658123957977164\n"
     ]
    }
   ],
   "source": [
    "print(mar1[\"PaceMinutes\"].mean()-low100,\n",
    "     hi100-mar1[\"PaceMinutes\"].mean(),\n",
    "     hi100-low100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0873700734359435 0.10993114878618293 0.19730122222212643\n"
     ]
    }
   ],
   "source": [
    "print(mar1[\"PaceMinutes\"].mean()-low1000,\n",
    "     hi1000-mar1[\"PaceMinutes\"].mean(),\n",
    "     hi1000-low1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 90% confidence interval, the female runners' pace times capture the true proportion of total runners in their given sample for the cases of n=100,1000, because the difference or deviation from the population mean of 2017 results appear to be the least. \n",
    "\n",
    "We will now calculate the same situation for a 95% confidence interval, where that interval can have no more than 5% of results be away from the true mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "tval20= stats.t.ppf(0.975,20)\n",
    "tval50= stats.t.ppf(0.975,50)\n",
    "tval100= stats.t.ppf(0.975,100)\n",
    "tval1000= stats.t.ppf(0.975,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 8.097621568850588 , high: 9.524045097816078\n"
     ]
    }
   ],
   "source": [
    "sm = df20[\"PaceMinutes\"].mean()\n",
    "psd = df20[\"PaceMinutes\"].std()\n",
    "low20=sm-((tval20*psd)/np.sqrt(20))\n",
    "hi20=sm+((tval20*psd)/np.sqrt(20))\n",
    "print(\"low:\", low20, \", high:\", hi20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 8.375971737211001 , high: 9.327361596122332\n"
     ]
    }
   ],
   "source": [
    "sm = df50[\"PaceMinutes\"].mean()\n",
    "psd = df50[\"PaceMinutes\"].std()\n",
    "low50=sm-((tval50*psd)/np.sqrt(50))\n",
    "hi50=sm+((tval50*psd)/np.sqrt(50))\n",
    "print(\"low:\", low50, \", high:\", hi50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 8.895104687678085 , high: 9.553228645655249\n"
     ]
    }
   ],
   "source": [
    "sm = df100[\"PaceMinutes\"].mean()\n",
    "psd = df100[\"PaceMinutes\"].std()\n",
    "low100=sm-((tval100*psd)/np.sqrt(100))\n",
    "hi100=sm+((tval100*psd)/np.sqrt(100))\n",
    "print(\"low:\", low100, \", high:\", hi100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 9.00058272222227 , high: 9.197883944444396\n"
     ]
    }
   ],
   "source": [
    "sm = df1000[\"PaceMinutes\"].mean()\n",
    "psd = df1000[\"PaceMinutes\"].std()\n",
    "low1000=sm-((tval1000*psd)/np.sqrt(1000))\n",
    "hi1000=sm+((tval1000*psd)/np.sqrt(1000))\n",
    "print(\"low:\", low1000, \", high:\", hi1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9903312268076245 0.4360923021578653 1.4264235289654899\n"
     ]
    }
   ],
   "source": [
    "print(mar1[\"PaceMinutes\"].mean()-low20,\n",
    "     hi20-mar1[\"PaceMinutes\"].mean(),\n",
    "     hi20-low20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7119810584472113 0.23940880046411905 0.9513898589113303\n"
     ]
    }
   ],
   "source": [
    "print(mar1[\"PaceMinutes\"].mean()-low50,\n",
    "     hi50-mar1[\"PaceMinutes\"].mean(),\n",
    "     hi50-low50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19284810798012764 0.4652758499970364 0.658123957977164\n"
     ]
    }
   ],
   "source": [
    "print(mar1[\"PaceMinutes\"].mean()-low100,\n",
    "     hi100-mar1[\"PaceMinutes\"].mean(),\n",
    "     hi100-low100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0873700734359435 0.10993114878618293 0.19730122222212643\n"
     ]
    }
   ],
   "source": [
    "print(mar1[\"PaceMinutes\"].mean()-low1000,\n",
    "     hi1000-mar1[\"PaceMinutes\"].mean(),\n",
    "     hi1000-low1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a 95% confidence interval, the sample size most accurate to the female runners' splits with regards to the overall mean split time in 2017 would be n=1000 since the deviation appears to be the least from the population mean split time of all racers in the 2017 race. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question #3</b>\n",
    "\n",
    "Use the bootstrap method to build empirical 90% confidence intervals for the true difference\n",
    "in the average paces between 2017 and 2015 for samples of size 30 and 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values of n are 30 and 50. Based off data from 2017 and 2015 samples\n",
    "# Take samples of mar1 and mar2 of n = 30, 50\n",
    "\n",
    "mar1['PaceList']=mar1['Pace'].apply(f)\n",
    "mar1['PaceMinutes']=mar1['PaceList'].apply(to_minutes)\n",
    "\n",
    "mar2['PaceList']=mar2['Pace'].apply(f)\n",
    "mar2['PaceMinutes']=mar2['PaceList'].apply(to_minutes)\n",
    "\n",
    "# T-distributions for 90% confidence intervals\n",
    "# These are the values for n=30, 50\n",
    "tval30 = stats.t.ppf(0.95,30)\n",
    "tval50 = stats.t.ppf(0.95,50)\n",
    "\n",
    "# Initializations working with given n values\n",
    "df1_30 = mar1.sample(30)\n",
    "df1_50 = mar1.sample(50)\n",
    "\n",
    "df2_30 = mar2.sample(30)\n",
    "df2_50 = mar2.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "bstrap1=[]\n",
    "xbar1=df1_30['PaceMinutes'].mean()\n",
    "for i in range(30):\n",
    "    newdf=df1_30.sample(frac=1,replace=True)\n",
    "    xstar=newdf['PaceMinutes'].mean()\n",
    "    bstrap1.append(xstar-xbar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4586944444444442 0.40224999999999905\n"
     ]
    }
   ],
   "source": [
    "# To separate bootstrap under 90% quartile, one is 0.05, the other is 0.95\n",
    "a,b=np.quantile(bstrap1,0.05), np.quantile(bstrap1,0.95)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.507750000000001 9.368694444444444\n"
     ]
    }
   ],
   "source": [
    "# take difference of a or b from xbar, then do rest for other n values and its year's results\n",
    "print(xbar1-b, xbar1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.925 8.85\n"
     ]
    }
   ],
   "source": [
    "# determine if the median is within the confidence interval\n",
    "# If it is then it would be a good prediction of the range of the pace value. \n",
    "M=df1_30['PaceMinutes'].median()\n",
    "print(M, mar1['PaceMinutes'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "bstrap2=[]\n",
    "xbar2=df1_50['PaceMinutes'].mean()\n",
    "for i in range(50):\n",
    "    newdf=df1_50.sample(frac=1,replace=True)\n",
    "    xstar=newdf['PaceMinutes'].mean()\n",
    "    bstrap2.append(xstar-xbar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.37993333333333335 0.2791000000000017\n"
     ]
    }
   ],
   "source": [
    "a,b=np.quantile(bstrap2,0.05), np.quantile(bstrap2,0.95)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.935233333333333 9.594266666666668\n"
     ]
    }
   ],
   "source": [
    "print(xbar2-b, xbar2-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.075 8.85\n"
     ]
    }
   ],
   "source": [
    "M=df1_50['PaceMinutes'].median()\n",
    "print(M, mar1['PaceMinutes'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "bstrap3=[]\n",
    "xbar3=df2_30['PaceMinutes'].mean()\n",
    "for i in range(30):\n",
    "    newdf=df2_30.sample(frac=1,replace=True)\n",
    "    xstar=newdf['PaceMinutes'].mean()\n",
    "    bstrap3.append(xstar-xbar3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.273444444444445 0.26822222222222225\n"
     ]
    }
   ],
   "source": [
    "a,b=np.quantile(bstrap3,0.05), np.quantile(bstrap3,0.95)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.814 8.355666666666668\n"
     ]
    }
   ],
   "source": [
    "print(xbar3-b, xbar3-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.991666666666667 8.383333333333333\n"
     ]
    }
   ],
   "source": [
    "M=df2_30['PaceMinutes'].median()\n",
    "print(M, mar2['PaceMinutes'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "bstrap4=[]\n",
    "xbar4=df2_50['PaceMinutes'].mean()\n",
    "for i in range(50):\n",
    "    newdf=df2_50.sample(frac=1,replace=True)\n",
    "    xstar=newdf['PaceMinutes'].mean()\n",
    "    bstrap4.append(xstar-xbar4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.34246666666666514 0.22644999999999968\n"
     ]
    }
   ],
   "source": [
    "a,b=np.quantile(bstrap4,0.05), np.quantile(bstrap4,0.95)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.287883333333333 8.856799999999998\n"
     ]
    }
   ],
   "source": [
    "print(xbar4-b, xbar4-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.291666666666668 8.383333333333333\n"
     ]
    }
   ],
   "source": [
    "M=df2_50['PaceMinutes'].median()\n",
    "print(M, mar2['PaceMinutes'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question #4</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% confidence intervals for 2017 race (0.05, 0.95)\n",
    "# n=30, 100, 1000\n",
    "\n",
    "# T-distributions for 90% confidence intervals\n",
    "# These are the values for n=30, 50\n",
    "tval30 = stats.t.ppf(0.95,30)\n",
    "tval100 = stats.t.ppf(0.95,50)\n",
    "tval1000 = stats.t.ppf(0.95,1000)\n",
    "\n",
    "# Create samples for all respective values n\n",
    "df30 = mar1.sample(30)\n",
    "df100 = mar1.sample(100)\n",
    "df1000 = mar1.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bootstrap for n=30\n",
    "\n",
    "# Take sample mean of n and then create/replace new samples within n quantity and see how much\n",
    "# mean changes by from original sample mean\n",
    "bstrap=[]\n",
    "xbar = df30[\"PaceMinutes\"].mean()\n",
    "for a in range(30):\n",
    "    newdf=df30.sample(frac=1,replace=True)\n",
    "    xstar=newdf['PaceMinutes'].mean()\n",
    "    bstrap.append(xstar-xbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4796111111111127 0.4821944444444422\n",
      "8.506138888888893 9.467944444444448\n"
     ]
    }
   ],
   "source": [
    "a,b=np.quantile(bstrap,0.05),np.quantile(bstrap,0.95)\n",
    "print(a,b)\n",
    "\n",
    "# return the confidence interval values of sample of the pace times\n",
    "print(xbar-b,xbar-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use bootstrap for n=100\n",
    "# Same applies here\n",
    "\n",
    "bstrap=[]\n",
    "xbar = df100[\"PaceMinutes\"].mean()\n",
    "for a in range(100):\n",
    "    newdf=df100.sample(frac=1,replace=True)\n",
    "    xstar=newdf['PaceMinutes'].mean()\n",
    "    bstrap.append(xstar-xbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3400500000000046 0.2783749999999981\n",
      "8.685125000000003 9.303550000000007\n"
     ]
    }
   ],
   "source": [
    "a,b=np.quantile(bstrap,0.05),np.quantile(bstrap,0.95)\n",
    "print(a,b)\n",
    "\n",
    "# return the confidence interval values of sample of the pace times\n",
    "print(xbar-b,xbar-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use bootstrap for n=1000\n",
    "# Same applies here\n",
    "\n",
    "bstrap=[]\n",
    "xbar = df1000[\"PaceMinutes\"].mean()\n",
    "for a in range(1000):\n",
    "    newdf=df1000.sample(frac=1,replace=True)\n",
    "    xstar=newdf['PaceMinutes'].mean()\n",
    "    bstrap.append(xstar-xbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08019083333333069 0.0806691666666765\n",
      "8.984064166666643 9.144924166666652\n"
     ]
    }
   ],
   "source": [
    "a,b=np.quantile(bstrap,0.05),np.quantile(bstrap,0.95)\n",
    "print(a,b)\n",
    "\n",
    "# return the confidence interval values of sample of the pace times\n",
    "print(xbar-b,xbar-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
